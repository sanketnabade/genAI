{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0a0b814",
   "metadata": {},
   "source": [
    "### Introduction to Text Preprocessing and Stemming\n",
    "\n",
    "In NLP, **text preprocessing** is a crucial step that prepares raw text for machine learning models. We've already covered **tokenization**, which breaks text into words. Now, let's explore **stemming**, a process that reduces words to their root form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006ed1ec",
   "metadata": {},
   "source": [
    "### What is Stemming?\n",
    "\n",
    "**Stemming** is the process of reducing a word to its **word stem**, or **root form**, by removing affixes (prefixes and suffixes). This is an essential technique for text analysis because it helps consolidate different forms of the same word into a single representation. For instance, in a product review dataset, words like \"eating,\" \"eats,\" and \"eaten\" all convey the same core meaning. By stemming, we can reduce all these words to a common root like \"eat.\" This reduces the total number of unique words (the vocabulary) in the dataset, simplifying the input for our model and making it more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c5549a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"eating\", \"eats\", \"eaten\", \"writing\", \"writes\", \"programming\", \"programs\", \"history\", \"finally\", \"finalized\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a49ca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d2f78f",
   "metadata": {},
   "source": [
    "### Stemming with NLTK\n",
    "\n",
    "The NLTK library provides several stemming algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6689f275",
   "metadata": {},
   "source": [
    "#### **Porter Stemmer**\n",
    "\n",
    "The **Porter Stemmer** is one of the most widely used and oldest stemming algorithms. It applies a series of rules to remove common English suffixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dba94511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Porter Stemmer Output ---\n",
      "eating          -> eat\n",
      "eats            -> eat\n",
      "eaten           -> eaten\n",
      "writing         -> write\n",
      "writes          -> write\n",
      "programming     -> program\n",
      "programs        -> program\n",
      "history         -> histori\n",
      "finally         -> final\n",
      "finalized       -> final\n",
      "\n",
      "--- Additional Examples ---\n",
      "congratulations -> congratul\n",
      "sitting         -> sit\n",
      "fairly          -> fairli\n",
      "sportingly      -> sportingli\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Initialize the Porter Stemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "\n",
    "print(\"--- Porter Stemmer Output ---\")\n",
    "for word in words:\n",
    "    stemmed_word = porter.stem(word)\n",
    "    print(f\"{word:<15} -> {stemmed_word}\")\n",
    "\n",
    "print(\"\\n--- Additional Examples ---\")\n",
    "print(f\"{'congratulations':<15} -> {porter.stem('congratulations')}\")\n",
    "print(f\"{'sitting':<15} -> {porter.stem('sitting')}\")\n",
    "print(f\"{'fairly':<15} -> {porter.stem('fairly')}\")\n",
    "print(f\"{'sportingly':<15} -> {porter.stem('sportingly')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db143e6e",
   "metadata": {},
   "source": [
    "\n",
    "**Observation:** While the Porter Stemmer works well for words like \"eating\" and \"eating\" (stemming them to \"eat\"), it has limitations. It often produces a stem that is not a valid word, such as \"congratul\" from \"congratulations.\" It also fails to reduce \"eaten\" to \"eat.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c445bbcc",
   "metadata": {},
   "source": [
    "#### **Snowball Stemmer**\n",
    "\n",
    "The **Snowball Stemmer**, also known as the **Porter2 Stemmer**, is an improved version of the Porter Stemmer. It supports more languages and often provides more accurate stems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5edd9a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Snowball Stemmer Output ---\n",
      "eating          -> eat\n",
      "eats            -> eat\n",
      "eaten           -> eaten\n",
      "writing         -> write\n",
      "writes          -> write\n",
      "programming     -> program\n",
      "programs        -> program\n",
      "history         -> histori\n",
      "finally         -> final\n",
      "finalized       -> final\n",
      "\n",
      "--- Comparing Stemmers ---\n",
      "fairly          -> Porter: fairli, Snowball: fair\n",
      "sportingly      -> Porter: sportingli, Snowball: sport\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Initialize the Snowball Stemmer for English\n",
    "snowball = SnowballStemmer(\"english\")\n",
    "\n",
    "print(\"\\n--- Snowball Stemmer Output ---\")\n",
    "for word in words:\n",
    "    stemmed_word = snowball.stem(word)\n",
    "    print(f\"{word:<15} -> {stemmed_word}\")\n",
    "\n",
    "print(\"\\n--- Comparing Stemmers ---\")\n",
    "print(f\"{'fairly':<15} -> Porter: {porter.stem('fairly')}, Snowball: {snowball.stem('fairly')}\")\n",
    "print(f\"{'sportingly':<15} -> Porter: {porter.stem('sportingly')}, Snowball: {snowball.stem('sportingly')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916ac50f",
   "metadata": {},
   "source": [
    "**Observation:** The Snowball Stemmer generally produces better results. For example, it correctly stems \"fairly\" to \"fair\" and \"sportingly\" to \"sport.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40d6858",
   "metadata": {},
   "source": [
    "#### **Regexp Stemmer**\n",
    "\n",
    "The **Regexp Stemmer** allows you to define your own stemming rules using **regular expressions**. This offers more control but requires a good understanding of regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a4225b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Regexp Stemmer Output ---\n",
      "eating          -> eat\n",
      "writes          -> write\n",
      "disable         -> dis\n",
      "finalize        -> finaliz\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "\n",
    "# Initialize RegexpStemmer with a regex pattern to remove common suffixes\n",
    "# The pattern '(ing|s|e|able)$' matches 'ing', 's', 'e', or 'able' at the end of a word.\n",
    "regexp_stemmer = RegexpStemmer('(ing|s|e|able)$')\n",
    "custom_words = [\"eating\", \"writes\", \"disable\", \"finalize\"]\n",
    "\n",
    "print(\"\\n--- Regexp Stemmer Output ---\")\n",
    "for word in custom_words:\n",
    "    stemmed_word = regexp_stemmer.stem(word)\n",
    "    print(f\"{word:<15} -> {stemmed_word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553b5067",
   "metadata": {},
   "source": [
    "### Limitations of Stemming\n",
    "\n",
    "Despite its usefulness, **stemming** has a major drawback: it is a **rule-based process** that often creates stems that are not actual words. This is because it doesn't consider the grammatical context of a word. For example, the Snowball Stemmer reduces \"goes\" to \"goe,\" which is grammatically incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46648c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goes -> Porter: goe, Snowball: goe\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'goes':<1} -> Porter: {porter.stem('goes')}, Snowball: {snowball.stem('goes')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021db0bb",
   "metadata": {},
   "source": [
    "This is where **lemmatization** comes in. Unlike stemming, **lemmatization** uses a dictionary and morphological analysis to return a grammatically correct base form (**lemma**) of a word. It is more computationally intensive but provides a more accurate result. For applications like chatbots or machine translation, where grammatical correctness is crucial, lemmatization is often the preferred choice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
